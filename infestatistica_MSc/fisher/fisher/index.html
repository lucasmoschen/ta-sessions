<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="../../../img/favicon.ico">

    
    <title>Informa√ß√£o de Fisher e Cram√©r-Rao - Teaching Assistance</title>
    

    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/v4-shims.css">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hack-font@3.3.0/build/web/hack.min.css">
    <link href='//rsms.me/inter/inter.css' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="../../../css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="../../../css/base.min.css" rel="stylesheet">
    <link href="../../../css/cinder.min.css" rel="stylesheet">

    
        
        <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/styles/github.min.css">
        
    

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
            <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
        <![endif]-->

    

     
</head>

<body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->

            
              <a class="navbar-brand" href="../../..">Teaching Assistance</a>
            
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="../../..">Home</a>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Gradua√ß√£o <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../alglin/info/">√Ålgebra Linear</a>
</li>

                        
                            
<li >
    <a href="../../../analisenum/info/">An√°lise Num√©rica</a>
</li>

                        
                            
<li >
    <a href="../../../curvas/info/">Curvas</a>
</li>

                        
                            
<li >
    <a href="../../../edo/info/">Equa√ß√µes Diferenciais Ordin√°rias</a>
</li>

                        
                            
<li >
    <a href="../../../edp/info/">Equa√ß√µes Diferenciais Parciais</a>
</li>

                        
                            
<li >
    <a href="../../../infestatistica_BSc/info/">Infer√™ncia Estat√≠stica</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">P√≥s-gradua√ß√£o <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../functional_analysis/info/">An√°lise Funcional</a>
</li>

                        
                            
<li >
    <a href="../../../bayesian/info/">Estat√≠stica Bayesiana</a>
</li>

                        
                            
<li >
    <a href="../../info/">Infer√™ncia Estat√≠stica</a>
</li>

                        
                        </ul>
                    </li>
                
                
                </ul>

            <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                            <i class="fas fa-search"></i> Search
                        </a>
                    </li>
                    <li>
                        <a href="https://lucasmoschen.github.io">P√°gina Inicial</a>
                    </li>
            </ul>
        </div>
    </div>
</div>

    <div class="container">
        
        
        <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="first-level active"><a href="#informacao-de-fisher-e-cramer-rao">Informa√ß√£o de Fisher e Cram√©r-Rao</a></li>
            <li class="second-level"><a href="#exemplo-construtivo">Exemplo Construtivo</a></li>
                
            <li class="second-level"><a href="#limites-inferiores-para-a-variancia">Limites inferiores para a vari√¢ncia</a></li>
                
                <li class="third-level"><a href="#desigualdade-da-variancia">Desigualdade da vari√¢ncia</a></li>
                <li class="third-level"><a href="#limite-inferior-de-cramer-rao">Limite inferior de Cram√©r-Rao</a></li>
                <li class="third-level"><a href="#desigualdade-de-chapman-robbins">Desigualdade de Chapman-Robbins</a></li>
                <li class="third-level"><a href="#sistema-de-bhattacharyya">Sistema de Bhattacharyya</a></li>
                <li class="third-level"><a href="#desigualdade-de-cramer-rao-multidimensional">Desigualdade de Cram√©r-Rao multidimensional</a></li>
            <li class="second-level"><a href="#exemplo-numerico-do-limite-de-cramer-rao">Exemplo Num√©rico do limite de Cram√©r-Rao</a></li>
                
    </ul>
</div></div>
        <div class="col-md-9" role="main">

<h1 id="informacao-de-fisher-e-cramer-rao">Informa√ß√£o de Fisher e Cram√©r-Rao</h1>
<p>Seja <script type="math/tex">X</script> uma vari√°vel aleat√≥ria cuja distribui√ß√£o depende de <script type="math/tex">\theta</script> com densidade <script type="math/tex">f(x|\theta)</script>. As condi√ß√µes de regularidade FI s√£o </p>
<ol>
<li>
<p>A derivada de <script type="math/tex">f(x|\theta)</script> com respeito a <script type="math/tex">\theta</script> existe com probabilidade 1.</p>
</li>
<li>
<p>Podemos diferenciar <script type="math/tex">\int f(x|\theta) d\mu(x)</script> sob o sinal da integra√ß√£o. <a href="https://en.wikipedia.org/wiki/Leibniz_integral_rule#:~:text=General%20form%3A%20Differentiation%20under%20the%20integral%20sign,-Theorem.&amp;text=That%20is%2C%20it%20is%20related,as%20the%20Leibniz%20integral%20rule.&amp;text=the%20change%20of%20order%20of%20integration%20(integration%20under%20the%20integral,%3B%20i.e.%2C%20Fubini's%20theorem).">(Veja aqui)</a>.</p>
</li>
<li>
<p>O conjunto <script type="math/tex">C = \{x: f(x|\theta) > 0\}</script> n√£o depende de <script type="math/tex">\theta</script>.</p>
</li>
</ol>
<p>Assuma as condi√ß√µes FI. 
A <strong>informa√ß√£o de Fisher</strong> √© definida como 
<script type="math/tex; mode=display">
I_{\mathcal{X}}(\theta) = \mathbb{E}_{\theta}\left[\left(\frac{d}{d\theta} \log f(x|\theta)\right)^2\right].
</script>
A fun√ß√£o <script type="math/tex">\partial \log f(X|\theta)/d\theta</script> √© chamada de <strong>fun√ß√£o score</strong>. </p>
<p>Se <script type="math/tex">\theta \in \mathbb{R}^k</script>, definimos as <strong>matrix informa√ß√£o de Fisher</strong> como 
<script type="math/tex; mode=display">
I_{\mathcal{X}, i,j }(\theta) = \operatorname{Cov}_{\theta}\left(\frac{\partial}{\partial \theta_i} \log f(x|\theta), \frac{\partial}{\partial \theta_j} \log f(x|\theta) \right).
</script>
</p>
<p>Agora seja <script type="math/tex">X = (X_1, \dots, X_n)</script> uma amostra aleat√≥ria e <script type="math/tex">f_n(x|\theta)</script> a densidade conjunta de <script type="math/tex">X</script>.
Denote <script type="math/tex">\lambda_n(x|\theta) = \log f_n(x|\theta)</script>. 
Como definimos, a informa√ß√£o de Fisher √© <script type="math/tex">I_n(\theta) = \mathbb{E}_{\theta}\{[\lambda_n'(X|\theta)]^2\}</script>. 
Como <script type="math/tex">\log f_n(x|\theta) = \sum_{i=1}^n \log f(x_i|\theta)</script>, temos que 
<script type="math/tex; mode=display">
I_n(\theta) = nI_{\mathcal{X}}(\theta).
</script>
Portanto, para amostras aleat√≥rias, basta calcular a informa√ß√£o considerando a densidade de uma vari√°vel aleat√≥ria. </p>
<p><strong>Teorema:</strong> Se valem as condi√ß√µes de regularidade FI, a m√©dia da fun√ß√£o score √© 0, isto √©, 
<script type="math/tex; mode=display">
\mathbb{E}_{\theta}\left[\frac{d}{d\theta} \log f(X|\theta)\right] = 0,
</script>
pois podemos tirar a derivada do valor esperado e, ent√£o, basta ver que a integral da densidade √© constante igual a <script type="math/tex">1</script>. 
Logo, vale que a derivada √© nula.
Al√©m do mais,
<script type="math/tex; mode=display">
I_{\mathcal{X}}(\theta) = -\mathbb{E}_{\theta}\left[\frac{d^2}{d\theta^2} \log f(X|\theta)\right]
</script>
</p>
<p>Esse resultado se estende para mais dimens√µes, com 
<script type="math/tex; mode=display">
I_{\mathcal{X}, i,j}(\theta) = -\mathbb{E}_{\theta}\left[\frac{\partial^2}{\partial \theta_i \partial \theta_j} \log f(X|\theta)\right].
</script>
</p>
<pre class="highlight"><code class="language-python">import numpy as np
from scipy.stats import norm
from scipy.misc import derivative
from scipy.optimize import curve_fit 

import matplotlib.pyplot as plt 
from seaborn import violinplot
import inspect</code></pre>
<h2 id="exemplo-construtivo">Exemplo Construtivo</h2>
<p>Vamos pensar num caso bem simples: amostra aleat√≥ria <script type="math/tex">X_1, ..., X_n \sim \text{Normal}(\mu, \sigma^2)</script>, onde o par√¢metro <script type="math/tex">\sigma^2</script> √© conhecido e <script type="math/tex">\mu</script> n√£o.  </p>
<p>De forma direta, poder√≠amos perguntar qual a Informa√ß√£o de Fisher (ou Informa√ß√£o Diferencial) da amostra aleat√≥ria sobre o par√¢metro desconhecido <script type="math/tex">\mu</script>. </p>
<ol>
<li>Vamos encontrar a distribui√ß√£o conjunta:</li>
</ol>
<p>
<script type="math/tex; mode=display">f(x|\mu) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left[-\frac{1}{2}\frac{(x - \mu)^2}{\sigma^2}\right]</script>
</p>
<p>
<script type="math/tex; mode=display">
\begin{split}
f_n(x|\mu) &= \prod_{i=1}^n f(x_i|\mu) = \frac{1}{(2\pi\sigma^2)^{n/2}}\exp\left[-\frac{1}{2\sigma^2}\sum_{i=1}^n (x_i - \mu)^2\right] \\ 
&= \frac{1}{(2\pi\sigma^2)^{n/2}}\exp\left[-\frac{1}{2\sigma^2}\sum_{i=1}^n (x_i^2 - 2x_i\mu + \mu^2)\right] \\
&= \frac{1}{(2\pi\sigma^2)^{n/2}}\exp\left[-\frac{1}{2\sigma^2}\left(\sum_{i=1}^n x_i^2 - 2n\bar{x}_n\mu + n\mu^2\right)\right] \\
&= \frac{1}{(2\pi\sigma^2)^{n/2}}\exp\left[-\frac{1}{2\sigma^2}\sum_{i=1}^n x_i^2\right]\exp\left[-\frac{1}{2\sigma^2}\left(- 2n\bar{x}_n\mu + n\mu^2\right)\right]
\end{split}
</script>
</p>
<ol>
<li>Vamos encontrar a verossimilhan√ßa: √© a distribui√ß√£o conjunta como fun√ß√£o do par√¢metro! </li>
</ol>
<p>
<script type="math/tex; mode=display">f_n(x|\mu) = \frac{1}{(2\pi\sigma^2)^{n/2}}\exp\left[-\frac{1}{2\sigma^2}\sum_{i=1}^n x_i^2\right]\exp\left[-\frac{1}{2\sigma^2}\left(- 2n\bar{x}_n\mu + n\mu^2\right)\right]</script>
</p>
<p>Vamos comparar para <script type="math/tex">\sigma = 1</script> e <script type="math/tex">\sigma = 5</script>
</p>
<pre class="highlight"><code class="language-python">loglikelihood = lambda mu, sigma, x: np.sum(np.log([norm(loc = mu, scale = sigma).pdf(xi) for xi in x]), axis = 0)</code></pre>
<pre class="highlight"><code class="language-python">sigmas = [1,3,5,10]
mu_true = 5

mu_range = np.linspace(0,10,1000)</code></pre>
<pre class="highlight"><code class="language-python">fig,ax = plt.subplots(2,2,figsize = (16, 10))

fig.suptitle('Comparando Log-verossimilhan√ßas da Distribui√ß√£o Normal')

def generate_curves(sigma, ax, n = 20, n_times = 50): 

    for i in range(n_times):

        x = np.random.normal(loc = mu_true, scale = sigma, size = n)
        logvalues = loglikelihood(mu_range, sigma, x)

        ax.plot(mu_range, logvalues, color = 'blue', alpha = 0.2)

    ax.vlines(mu_true, ymin = ax.get_ylim()[0], ymax = ax.get_ylim()[1], linestyle = '--')

    ax.set_title(r'$\sigma =$ {}'.format(sigma))
    ax.set_xlabel(r'$\mu$')

generate_curves(sigmas[0], ax[0][0])
generate_curves(sigmas[1], ax[0][1])
generate_curves(sigmas[2], ax[1][0])
generate_curves(sigmas[3], ax[1][1])    </code></pre>
<p><img alt="png" src="../output_5_0.png" /></p>
<ol>
<li>Vamos ver como se comporta derivada. Esse √© o score: </li>
</ol>
<p>
<script type="math/tex; mode=display">\lambda '_n(y|\mu) = \frac{1}{\sigma^2}\left(n\bar{x}_n - \mu\right)</script>
</p>
<pre class="highlight"><code class="language-python">score = lambda mu, sigma, x: derivative(loglikelihood, mu, dx = 1e-5, args = (sigma, x))  

fig,ax = plt.subplots(2,2,figsize = (16, 10))

fig.suptitle('Comparando Scores da Distribui√ß√£o Normal')

def generate_curves(sigma, ax, n = 20, n_times = 50): 

    for i in range(n_times):

        x = np.random.normal(loc = mu_true, scale = sigma, size = n)
        scorevalues = score(mu_range, sigma, x)

        ax.plot(mu_range, scorevalues, color = 'blue', alpha = 0.2)

    ax.vlines(mu_true, ymin = ax.get_ylim()[0], ymax = ax.get_ylim()[1], linestyle = '--')

    ax.set_title(r'$\sigma =$ {}'.format(sigma))
    ax.set_xlabel(r'$\mu$')

    ax.set_ylim((-10,10))

generate_curves(sigmas[0], ax[0][0])
generate_curves(sigmas[1], ax[0][1])
generate_curves(sigmas[2], ax[1][0])
generate_curves(sigmas[3], ax[1][1])    </code></pre>
<p><img alt="png" src="../output_7_0.png" /></p>
<pre class="highlight"><code class="language-python">fig,ax = plt.subplots(2,2,figsize = (16, 10))

fig.suptitle('Comparando Histogramas dos Scores para mu')

def generate_histograms(mu, sigma, ax, n = 15, n_times = 100): 

    scorevalues = []
    for i in range(n_times):

        x = np.random.normal(loc = mu_true, scale = sigma, size = n)
        scorevalues.append(score(mu, sigma, x))

    violinplot(scorevalues, ax = ax)

    ax.set_title(r'$\sigma =$ {}'.format(sigma))
    ax.set_xlabel('score')

generate_histograms(5, sigmas[0], ax[0][0])
generate_histograms(5, sigmas[1], ax[0][1])
generate_histograms(5, sigmas[2], ax[1][0])
generate_histograms(5, sigmas[3], ax[1][1])    </code></pre>
<p><img alt="png" src="../output_8_0.png" /></p>
<ol>
<li>A informa√ß√£o de Fisher √© a Vari√¢ncia da fun√ß√£o score em <script type="math/tex">X</script>, isto √©: </li>
</ol>
<p>
<script type="math/tex; mode=display">
\begin{split}
I_n(\mu) &= Var(\lambda '_n(x|p)) = E[(\lambda '_n(x|p))^2] - E[\lambda '_n(x|p)]^2\\ 
&= \frac{1}{\sigma^4}Var\left[n\bar{x}_n - \mu\right] \\
&= \frac{n^2}{\sigma^4}Var(\bar{x}_n) \\
&= \frac{n^2\sigma^2}{n\sigma^4} \\
&= \frac{n}{\sigma^2}
\end{split}
</script>
</p>
<h2 id="limites-inferiores-para-a-variancia">Limites inferiores para a vari√¢ncia</h2>
<p>Para estimadores n√£o enviesados, o erro quadr√°tico se iguala √† vari√¢ncia. 
Como nem sempre √© poss√≠vel obter valores exatos para vari√¢ncia, √© de interesse procurar por limites inferiores desses valores. 
Mais do que isso, se encontramos um estimador cuja vari√¢ncia seja um limite inferior, estaremos encontrando um UMVUE.</p>
<h3 id="desigualdade-da-variancia">Desigualdade da vari√¢ncia</h3>
<p>A desigualdade de Cauchy-Schwarz para vari√°veis aleat√≥rias, tratando a covari√¢ncia como um produto interno nesse espa√ßo, √© escrita da seguinte forma:
<script type="math/tex; mode=display">
|\operatorname{Cov}(X,Y)| \le \sqrt{\operatorname{Var}(X)}\sqrt{\operatorname{Var}(Y)}
</script>
</p>
<h3 id="limite-inferior-de-cramer-rao">Limite inferior de Cram√©r-Rao</h3>
<p>Sejam <script type="math/tex">I_{\mathcal{X}}(\theta)</script> a <a href="https://lucasmoschen.github.io/ta-sessions/infestatistica_MSc/fisher/fisher">informa√ß√£o de Fisher</a> e <script type="math/tex">\phi(X)</script> uma estat√≠stica com esperan√ßa finita. Suponha que valha algumas condi√ß√µes de regularidade(XXX: Quais?) e que <script type="math/tex">\forall \theta, I_{\mathcal{X}}(\theta) > 0</script>. 
Ent√£o 
<script type="math/tex; mode=display">
\operatorname{Var}_{\theta}(\phi(X)) \ge \frac{\left(\frac{d}{d\theta} \mathbb{E}_{\theta} \phi(X) \right)^2}{I_{\mathcal{X}}(\theta)}.
</script>
</p>
<p>Observe que se <script type="math/tex">\phi(X)</script> √© n√£o enviesado, ent√£o o limite inferior da vari√¢ncia √© o inverso da informa√ß√£o de Fisher.</p>
<hr />
<p><code>üìù</code> <strong>Exemplo (Normal)</strong></p>
<p>Seja <script type="math/tex">X \sim N(\theta, b)</script> com <script type="math/tex">b</script> fixo. 
Um estimador para <script type="math/tex">\theta</script> √© <script type="math/tex">\phi(X) = X</script>, que √© n√£o enviesado, em particular. 
A informa√ß√£o de Fisher √© 
<script type="math/tex; mode=display">
I_{\mathcal{X}}(\theta) = - \mathbb{E}_{\theta}\left[\frac{d^2}{d\theta^2} \log f(X|\theta) \right] = 1/b,
</script>
o que implica que <script type="math/tex">\operatorname{Var}(\phi(X))</script> √© limitado inferiormente por <script type="math/tex">b</script>. S√≥ que sabemos que ele atinge esse valor.
Portanto, esse estimador √© UMVUE, pois tem vari√¢ncia m√≠nima.</p>
<hr />
<p>A desigualdade de Cram√©r-Rao √© uma consequ√™ncia da desigualdade de Cauchy-Schwarz. 
Esta √∫ltima diz que vale a igualdade se, e somente se, os fatores s√£o linearmente independentes. 
No nosso, caso, isso significa que a desigualdade de Cram√©r-Rao se torna uma igualdade se, e somente se, <script type="math/tex">\phi(X)</script> e a fun√ß√£o <script type="math/tex">\frac{d}{d\theta}\log f(X|\theta)</script> s√£o linearmente relacionadas, isto √©,
<script type="math/tex; mode=display">
\frac{d}{d\theta} \log f(X|\theta) = a(\theta)\phi(X) + b(\theta).
</script>
Resolvendo essa equa√ß√£o, obtemos que 
<script type="math/tex; mode=display">
f(X|\theta) = c(\theta)h(x)\exp\{\pi(\theta)\phi(x)\},
</script>
que pertence √† fam√≠lia exponencial.
Logo, se <script type="math/tex">\phi(X)</script> √© uma estat√≠stica suficiente para um par√¢metro de uma distribui√ß√£o vinda da fam√≠lia exponencial, a desigualdade de Cram√©r-Rao vira uma igualdade. Al√©m disso, essa √© √∫nica situa√ß√£o.</p>
<blockquote>
<p>Fora da fam√≠lia exponencial, a desigualdade de Cram√©r-Rao n√£o pode ser alcan√ßada! Se uma estat√≠stica tem vari√¢ncia igual ao limite inferior de Cram√©r-Rao, ele √© dito <strong>estimador eficiente</strong>.</p>
</blockquote>
<h3 id="desigualdade-de-chapman-robbins">Desigualdade de Chapman-Robbins</h3>
<p>Seja <script type="math/tex">m(\theta) = \mathbb{E}_{\theta}(\phi(X))</script> e <script type="math/tex">supp(\theta)</script> o suporte da distribui√ß√£o de <script type="math/tex">X</script>.
Assuma que para cada <script type="math/tex">\theta \in \Omega</script>, exista <script type="math/tex">\theta'\neq\theta</script> tal que <script type="math/tex">supp(\theta') \subseteq supp(\theta)</script> (isso acontece quando <script type="math/tex">supp \theta</script> √© o mesmo para todo <script type="math/tex">\theta</script>).
Ent√£o,
<script type="math/tex; mode=display">
\operatorname{Var}_{\theta}(\phi(X)) \ge \sup_{\theta ' : supp(\theta') \subseteq supp(\theta)} \left\{\frac{[m(\theta) - m(\theta ')]^2}{\mathbb{E}_{\theta}\left[\frac{f_{X|\theta}(X|\theta ')}{f_{X|\theta}(X|\theta)} - 1\right]^2}\right\}
</script>
</p>
<p>Note que essa desigualdade vale para casos mais gerais. 
Por√©m, ela tamb√©m √© consequ√™ncia da desigualdade de Cauchy-Schwarz.</p>
<h3 id="sistema-de-bhattacharyya">Sistema de Bhattacharyya</h3>
<p>Assuma as condi√ß√µes do Teorema de Cram√©r-Rao e que a derivada sob <script type="math/tex">\theta</script> pode passar sob o sinal de integra√ß√£o
Ent√£o <script type="math/tex">\operatorname{Var} \phi(X) \ge \gamma^T (\theta) J^{-1}(\theta)\gamma(\theta)</script>, 
em que 
<script type="math/tex; mode=display">
\gamma_i(\theta) = \frac{d^i}{d\theta^i}\mathbb{E}_{\theta}[\phi(X)], J_{ij}(\theta) = \operatorname{Cor}(\psi_i(X,\theta), \psi_j(X,\theta)), \psi_i(x,\theta) = \frac{1}{f(x|\theta)}\frac{d^i}{d\theta^i} f(x|\theta).
</script>
</p>
<p>Esse resultado √© uma consequ√™ncia direta de uma desigualdade envolvendo vari√¢ncia de um estimador e covari√¢ncias dele com outras fun√ß√µes dos dados e do par√¢metro.</p>
<h3 id="desigualdade-de-cramer-rao-multidimensional">Desigualdade de Cram√©r-Rao multidimensional</h3>
<p>Assumindo as condi√ß√µes do caso unidimensional mais que a matriz informa√ß√£o de Fisher seja positiva definida, ent√£o
<script type="math/tex; mode=display">
\operatorname{Var}_{\theta}(\phi(X)) \ge \gamma^T(\theta) I_X^{-1}(\theta)\gamma(\theta),
</script>
em que <script type="math/tex">\gamma_i(\theta) = \frac{d}{d\theta_i} \mathbb{E}_{\theta} \phi(X)</script>.</p>
<h2 id="exemplo-numerico-do-limite-de-cramer-rao">Exemplo Num√©rico do limite de Cram√©r-Rao</h2>
<p><a href="http://michal.rawlik.pl/2014/02/21/numerical-cramer-rao-bound-in-python/">Refer√™ncia</a></p>
<p>Considere um sinal (como uma m√∫sica) com tr√™s par√¢metros, amplitude, frequ√™ncia e fase inicia.</p>
<p>Saberemos o n√∫mero de amostras que sera 100Hz com n√≠vel de ru√≠do de 0.1 </p>
<pre class="highlight"><code class="language-python">s = lambda t,a,f,ph: a*np.sin(2*np.pi*f*t + ph) # fun√ß√£o que representa o sinal

p0 = [2,8,0]     # Amplitude, frequ√™ncia e fase inicial para testar 
noise = 0.1

T = np.linspace(0,1,100)   #100 valores entre 0 e 1 igualmente espa√ßados
plt.plot(T, s(T, *p0), '.-k')
plt.xlabel('Tempo (s)')
plt.title('Sinal')
plt.show()</code></pre>
<p><img alt="png" src="../output_13_0.png" /></p>
<p>Vamos usar <a href="https://docs.python.org/3/library/inspect.html">inspect</a> para nos ajudar a pegar labels das fun√ß√µes, isto √©, os par√¢metros necess√°rios das fun√ß√µes. Essa biblioteca fornece v√°rias fun√ß√µes de ajuda desse tipo. D√™ uma olhada. </p>
<pre class="highlight"><code class="language-python">parameters = str(inspect.signature(s)).strip('()').replace(' ', '').split(',')[1:]
p0dict = dict(zip(parameters, p0))
p0dict</code></pre>
<pre><code>{'a': 2, 'f': 8, 'ph': 0}
</code></pre>
<p>No caso geral, calcular a Matriz de Informa√ß√£o de Fisher n√£o √© trivial. Por isso, vamos calcular para o caso em que as medi√ß√µes s√£o de uma amostra com distribui√ß√£o multivariada normal, isto √©, √© uma distribui√ß√£o normal, s√≥ que em mais dimens√µes, em particular, 441 dimens√µes (n√∫mero de pontos no tempo)</p>
<p>Se calcularmos a informa√ß√£o de Fisher, podemos ver que:</p>
<p>
<script type="math/tex; mode=display">
\mathcal{I}_{mn} = \frac{1}{\sigma^2} \frac{\partial \mu^\mathrm{T}}{\partial \theta_m} \frac{\partial \mu}{\partial \theta_n} = \frac{1}{\sigma^2} \sum_k \frac{\partial \mu_k}{\partial \theta_m} \frac{\partial \mu_k}{\partial \theta_n}
</script>
</p>
<p>onde <script type="math/tex">\theta = [a,f,ph]^T</script>, <script type="math/tex">\mu = \mu(\theta)</script> √© o vetor m√©dia da normal multivariada e <script type="math/tex">\sigma^2</script> √© a vari√¢ncia de cada marginal da normal. N√£o se assuste. Na multivariada, temos uma matriz para indicar as vari√¢ncias (ela se chama Matriz de Covari√¢ncias, na verdade). O que estou dizendo √© que ela √© <script type="math/tex">\sigma^2</script> vezes a identidade. √â bom conhecer essa distribui√ß√£o!</p>
<p>Por enquando acredite em mim! Ou no <a href="https://en.wikipedia.org/wiki/Fisher_information#Multivariate_normal_distribution">Wikipedia</a>.</p>
<p>Vou chamar <script type="math/tex">D_{ik} = \frac{\partial \mu_k}{\partial \theta_i}</script>
</p>
<pre class="highlight"><code class="language-python"># Usamos ** para desempacotar elementos de um dicion√°rio.
string = "a: {a} f: {f} ph: {ph}".format(**p0dict)
print(string)</code></pre>
<pre><code>a: 2 f: 8 ph: 0
</code></pre>
<pre class="highlight"><code class="language-python">D = np.zeros((len(p0), len(T)))

# para cada par√¢metro
for i, parameter in enumerate(parameters):
    # para cada ponto no tempo
    for k, t in enumerate(T):

        func = lambda x: s(t, **dict(p0dict, **{parameter: x}))
        # Calculamos a derivada com respeito a x, que nesse caso √© o valor do parametro
        D[i,k] = derivative(func, p0dict[parameter], dx = 1e-4)   </code></pre>
<p>Veja que o tamanho de D √© o seguinte:</p>
<pre class="highlight"><code class="language-python">D.shape</code></pre>
<pre><code>(3, 100)
</code></pre>
<pre class="highlight"><code class="language-python">plt.plot(T, s(T, *p0), '--k', lw=2, label='Sinal')

for Di, parameter in zip(D, parameters):
    # Estamos acessando Di = linha_i(D)
    plt.plot(T, Di, '.-', label=parameter)

plt.legend()
plt.xlabel('Tempo (s)')
plt.show()</code></pre>
<p><img alt="png" src="../output_21_0.png" /></p>
<p>O que <script type="math/tex">D_{ik}</script> indica? √â a derivada da <script type="math/tex">k-√©sima</script> m√©dia com respeito ao i-√©simo par√¢metro. Logo indica o quanto o quando a amostra <script type="math/tex">k</script> afeta o par√¢metro <script type="math/tex">i</script>. Veja que quando temos picos no seno, teremos pico na amplitude,. Tamb√©m vemos que a fase inicial n√£o tem essa relev√¢ncia. Vemos tamb√©m que o sinal se torna mais e mais sens√≠vel √† frequ√™ncia. </p>
<p>Assim, podemos calular a informa√ß√£o de fisher, usando <a href="https://numpy.org/doc/stable/reference/generated/numpy.einsum.html">einsum</a></p>
<pre class="highlight"><code class="language-python">I = 1/noise**2*np.einsum('mk,nk', D, D)
print(I)</code></pre>
<pre><code>[[ 4.95000000e+03 -5.64643569e+02 -3.43706036e-09]
 [-5.64643569e+02  2.68635205e+05  6.34601694e+04]
 [-3.43706036e-09  6.34601694e+04  2.01999999e+04]]
</code></pre>
<p>Podemos calcular o limite de Cram√©r-Rao para qualquer estimador n√£o enviesado. Nesse caso, veja <a href="https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound#Multivariate_case">aqui</a> para mais detalhes. Mas n√£o se incomode com os detalhes, se preferir. </p>
<pre class="highlight"><code class="language-python">iI = np.linalg.inv(I)  

print('Cram√©r-Rao Limite Inferior')
for parameter, variance in zip(parameters, iI.diagonal()):
    print('{}: {:.2g}'.format(parameter, np.sqrt(variance)))</code></pre>
<pre><code>Cram√©r-Rao Limite Inferior
a: 0.014
f: 0.0038
ph: 0.014
</code></pre></div>
        
        
    </div>

    
      <footer class="col-md-12 text-center">
          
          
            <hr>
            <p>
            <small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</small>
            </p>
          

          
          
      </footer>
    
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="../../../js/bootstrap-3.0.3.min.js"></script>

    
    <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/highlight.min.js"></script>
        
    <script>hljs.initHighlightingOnLoad();</script>
    

    <script>var base_url = "../../.."</script>
    
    <script src="../../../js/base.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="../../../search/main.js"></script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal">
                    <span aria-hidden="true">&times;</span>
                    <span class="sr-only">Close</span>
                </button>
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form>
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>
    </body>

</html>
